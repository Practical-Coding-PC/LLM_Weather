import os
import sys
import warnings
import google.generativeai as genai
from typing import Optional, Dict, Any

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆë“¤ì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from repositories.chat_repository import ChatRepository
from repositories.chat_message_repository import ChatMessageRepository

from chatbot.utils.cctv_utils import find_nearest_cctv
from chatbot.gemini_functions import create_function_calling_model
from chatbot.function_handler import WeatherFunctionHandler
from forecast.forecast_service import ForecastService

# urllib3 ê²½ê³  ë¬´ì‹œ (macOS LibreSSL í˜¸í™˜ì„± ë¬¸ì œ)
warnings.filterwarnings("ignore", message="urllib3 v2 only supports OpenSSL 1.1.1+")


class ChatbotService:
    """
    ì±—ë´‡ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        # API í‚¤ ì„¤ì •
        self.GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
        self.CCTV_API_KEY = os.getenv('CCTV_API_KEY')
        
        # ForecastService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.forecast_service = ForecastService()
        
        # Function Handler ìƒì„±
        self.function_handler = WeatherFunctionHandler()
        
        # Gemini ëª¨ë¸ ì´ˆê¸°í™” (Function Calling ì§€ì›)
        if self.GEMINI_API_KEY:
            self.model = create_function_calling_model(self.GEMINI_API_KEY)
        else:
            self.model = None

    async def get_cctv_info(self, message: str) -> str:
        """
        ë©”ì‹œì§€ì—ì„œ CCTV ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•œë‹¤.
        
        Args:
            message (str): ì‚¬ìš©ì ë©”ì‹œì§€.
            
        Returns:
            str: CCTV ì •ë³´ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€.
        """
        try:
            cctv_data = await find_nearest_cctv(message)
            
            if cctv_data:
                return f"cctv_data:{cctv_data}"
            else:
                return "í•´ë‹¹ ì§€ì—­ì—ì„œ CCTVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì§€ì› ì§€ì—­: ì¶˜ì²œ, íš¨ìë™, ë…¸ì›, ì„œìš¸"
                
        except Exception as e:
            print(f"CCTV ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return "CCTV ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    async def get_default_response(self, message: str) -> str:
        """
        Gemini APIê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
        
        Args:
            message (str): ì‚¬ìš©ì ë©”ì‹œì§€.
            
        Returns:
            str: ê¸°ë³¸ ì‘ë‹µ ë©”ì‹œì§€ì¸ "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        """
        weather_keywords = ['ë‚ ì”¨', 'ê¸°ì˜¨', 'ì˜¨ë„', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'ì˜ˆë³´']
        cctv_keywords = ['cctv', 'CCTV', 'ì”¨ì”¨í‹°ë¹„', 'ìº ', 'ì¹´ë©”ë¼', 'ë„ë¡œ', 'êµí†µ', 'ì‹¤ì‹œê°„']

        # CCTV ìš”ì²­ í™•ì¸
        if any(keyword in message for keyword in cctv_keywords):
            return await self.get_cctv_info(message)
        
        # ë‚ ì”¨ ìš”ì²­ í™•ì¸
        elif any(keyword in message for keyword in weather_keywords):
            weather_request = self.forecast_service.analyze_weather_request(message)
            weather_info = self.forecast_service.get_weather_info(weather_request)
            return f"ë‚ ì”¨ ì •ë³´:\n\n{weather_info}"
        else:
            return "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    
    async def process_message(self, message: str, user_id: str, chat_id: Optional[int] = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì±—ë´‡ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
        
        Args:
            message (str): ì‚¬ìš©ì ë©”ì‹œì§€
            user_id (str): ì‚¬ìš©ì ID
            chat_id (int, optional): ì±„íŒ… ID
            
        Returns:
            dict: ì±—ë´‡ ì‘ë‹µê³¼ ì±„íŒ… IDë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        user_message = message.strip()
        
        if not user_message:
            raise ValueError("ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # ì±„íŒ… ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if not chat_id:
            chat_id = ChatRepository.create(user_id)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥
        user_message_id = ChatMessageRepository.create(
            chat_id=chat_id,
            role="user",
            content=user_message
        )
        
        # Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
        if not self.GEMINI_API_KEY:
            bot_response = await self.get_default_response(user_message)
        else:
            # CCTV ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            cctv_keywords = ['cctv', 'CCTV', 'ì”¨ì”¨í‹°ë¹„', 'ìº ', 'ì¹´ë©”ë¼', 'ë„ë¡œ', 'êµí†µ', 'ì‹¤ì‹œê°„']
            is_cctv_related = any(keyword in user_message for keyword in cctv_keywords)
            
            # ë‚ ì”¨ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            weather_keywords = [
                'ë‚ ì”¨', 'ê¸°ì˜¨', 'ì˜¨ë„', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'ìŠµë„', 'ë¯¸ì„¸ë¨¼ì§€', 
                'ìì™¸ì„ ', 'ì²´ê°ì˜¨ë„', 'ê°•ìˆ˜', 'êµ¬ë¦„', 'ë§‘ìŒ', 'íë¦¼', 'ì˜ˆë³´'
            ]
            is_weather_related = any(keyword in user_message for keyword in weather_keywords)
            
            if is_cctv_related:
                # CCTV ìš”ì²­ ì²˜ë¦¬
                bot_response = await self.get_cctv_info(user_message)
            elif is_weather_related:
                # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
                recent_messages = ChatMessageRepository.get_last_n_messages(chat_id, 20)
                
                # ë‚ ì”¨ ìš”ì²­ì„ Function Callingìœ¼ë¡œ ì²˜ë¦¬
                bot_response = await self.handle_weather_with_function_calling(
                    user_message, recent_messages
                )
            else:
                # ë‚ ì”¨ì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ
                recent_messages = ChatMessageRepository.get_last_n_messages(chat_id, 20)
                
                conversation_history = ""
                if recent_messages:
                    history_lines = []
                    for msg in recent_messages:
                        role_name = "ì‚¬ìš©ì" if msg['role'] == 'user' else "ì±—ë´‡"
                        history_lines.append(f"{role_name}: {msg['content']}")
                    conversation_history = "\n".join(history_lines)
                
                # ê°„ê²°í•œ ì¼ë°˜ ì‘ë‹µì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
                if conversation_history:
                    prompt = f"""
ì´ì „ ëŒ€í™”:
{conversation_history}

ì‚¬ìš©ì ì§ˆë¬¸: "{user_message}"

ë‹¹ì‹ ì€ ëŒ€í™”í˜• AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³  ì—°ì†ì„± ìˆëŠ” ëŒ€í™”ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì¡°ê±´:
1. ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€
2. ë„ì›€ì´ ë˜ê³  ì¹œê·¼í•œ ë§íˆ¬
3. ê°„ê²°í•˜ê³  ëª…í™•í•œ ë‹µë³€
4. 100ì ë‚´ì™¸ë¡œ ì‘ì„±
"""
                else:
                    prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{user_message}"

ë‹¹ì‹ ì€ ëŒ€í™”í˜• AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

ì¡°ê±´:
1. ë„ì›€ì´ ë˜ê³  ì¹œê·¼í•œ ë§íˆ¬
2. ê°„ê²°í•˜ê³  ëª…í™•í•œ ë‹µë³€
3. 100ì ë‚´ì™¸ë¡œ ì‘ì„±
"""
                
                try:
                    response = self.model.generate_content(prompt)
                    bot_response = response.text.strip()
                except Exception as e:
                    print(f"Gemini API ì˜¤ë¥˜: {e}")
                    bot_response = "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        
        # ë´‡ ì‘ë‹µì„ DBì— ì €ì¥
        bot_message_id = ChatMessageRepository.create(
            chat_id=chat_id,
            role="assistant",
            content=bot_response
        )
        
        return {"reply": bot_response, "chat_id": chat_id}
    
    def get_chat_messages(self, chat_id: int) -> Dict[str, Any]:
        """
        íŠ¹ì • ì±„íŒ…ì˜ ë©”ì‹œì§€ ê¸°ë¡ì„ ì¡°íšŒí•œë‹¤.
        
        Args:
            chat_id (int): ì±„íŒ… ID
            
        Returns:
            dict: ì±„íŒ… IDì™€ ë©”ì‹œì§€ ëª©ë¡ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        messages = ChatMessageRepository.get_by_chat_id(chat_id)
        return {"chat_id": chat_id, "messages": messages}
    
    def get_user_chats(self, user_id: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ ì±„íŒ… ëª©ë¡ì„ ì¡°íšŒí•œë‹¤.
        
        Args:
            user_id (str): ì‚¬ìš©ì ID
            
        Returns:
            dict: ì‚¬ìš©ì IDì™€ ì±„íŒ… ëª©ë¡ì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        chats = ChatRepository.get_by_user_id(user_id)
        return {"user_id": user_id, "chats": chats}
    
    async def handle_weather_with_function_calling(self, user_message: str, recent_messages: list = None) -> str:
        """
        Function Callingì„ ì‚¬ìš©í•´ì„œ ë‚ ì”¨ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤
        """
        try:
            # ëŒ€í™” ê¸°ë¡ êµ¬ì„±
            conversation_history = ""
            if recent_messages:
                history_lines = []
                for msg in recent_messages:
                    role_name = "ì‚¬ìš©ì" if msg['role'] == 'user' else "ì±—ë´‡"
                    history_lines.append(f"{role_name}: {msg['content']}")
                conversation_history = "\n".join(history_lines)
            
            # Function Callingì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ ë‚ ì”¨ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë‚ ì”¨ ì§ˆë¬¸ì„ ì •í™•íˆ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë‚ ì”¨ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ ì£¼ì„¸ìš”.

ì§€ì› ì§€ì—­: ì¶˜ì²œ, ë…¸ì›, ì„œìš¸, íš¨ìë™

í•¨ìˆ˜ ì„ íƒ ê·œì¹™:
1. "í˜„ì¬ ë‚ ì”¨", "ì§€ê¸ˆ ë‚ ì”¨", "ì˜¤ëŠ˜ ë‚ ì”¨", "ë‚ ì”¨ ì–´ë•Œ?" â†’ get_current_weather
2. "Nì‹œê°„ í›„" (1-6ì‹œê°„) â†’ get_specific_hour_forecast 
3. "Nì‹œê°„ í›„" (7-120ì‹œê°„) â†’ get_short_term_forecast
4. "ì¢…í•©", "ìì„¸íˆ", "ì „ì²´", "ì´ë²ˆ ì£¼" â†’ get_comprehensive_weather

ì¤‘ìš”: ì§€ì—­ëª…ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³ , ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ hours íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.
í•¨ìˆ˜ í˜¸ì¶œ í›„ ê²°ê³¼ë¥¼ ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."""
            
            if conversation_history:
                full_prompt = f"{system_prompt}\n\nì´ì „ ëŒ€í™”:\n{conversation_history}\n\nì‚¬ìš©ì: {user_message}"
            else:
                full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì: {user_message}"
            
            print(f"ğŸ¤– Function Calling ì‹œì‘: {user_message}")
            
            # Geminiì—ê²Œ ë©”ì‹œì§€ ì „ì†¡
            response = self.model.generate_content(full_prompt)
            
            # Function Callì´ ìˆëŠ”ì§€ í™•ì¸
            if response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'function_call') and part.function_call:
                        # Function Call ì‹¤í–‰
                        function_name = part.function_call.name
                        function_args = {}
                        
                        # ì¸ì ì¶”ì¶œ
                        for key, value in part.function_call.args.items():
                            function_args[key] = value
                        
                        print(f"ğŸ”¥ Function Call ì„¸ë¶€ì‚¬í•­:")
                        print(f"  - í•¨ìˆ˜ëª…: {function_name}")
                        print(f"  - ì¸ì: {function_args}")
                        
                        # í•¨ìˆ˜ ì‹¤í–‰
                        function_result = self.function_handler.execute_function(
                            function_name, function_args
                        )
                        
                        print(f"ğŸŒŸ Function ê²°ê³¼ ë‚´ìš©:")
                        print(f"  - ê²°ê³¼ ê¸¸ì´: {len(function_result)} ë¬¸ì")
                        print(f"  - ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {function_result[:100]}...")
                        
                        # ê²°ê³¼ë¥¼ Geminiì—ê²Œ ë‹¤ì‹œ ì „ì†¡í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
                        final_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_message}"

ë‚ ì”¨ ë°ì´í„°:
{function_result}

ìœ„ ë‚ ì”¨ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ì‚¬ìš©ìê°€ ë¬»ëŠ” ì‹œê°„ëŒ€ì˜ ë‚ ì”¨ì— ì§‘ì¤‘í•´ì„œ ë‹µë³€
- ê¸°ì˜¨, í•˜ëŠ˜ìƒíƒœ, ê°•ìˆ˜í™•ë¥  ë“± í•µì‹¬ ì •ë³´ í¬í•¨
- ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬
- 100-150ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ì´ëª¨ì§€ë‚˜ ê¸°í˜¸ ì‚¬ìš©í•˜ì—¬ ë” ì¹œê·¼í•˜ê²Œ"""
                        
                        # ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± (Function Calling ì—†ì´)
                        import google.generativeai as genai
                        simple_model = genai.GenerativeModel("models/gemini-1.5-flash-latest")
                        final_response = simple_model.generate_content(final_prompt)
                        
                        return final_response.text.strip()
                
                # Function Callì´ ì—†ìœ¼ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
                if response.text:
                    return response.text.strip()
            
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"Function Calling ì˜¤ë¥˜: {e}")
            # Fallback: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            weather_request = self.forecast_service.analyze_weather_request(user_message)
            weather_info = self.forecast_service.get_weather_info(weather_request)
            return f"ë‚ ì”¨ ì •ë³´:\n\n{weather_info}"
    
    def get_supported_locations(self) -> Dict[str, Any]:
        """
        ì§€ì›ë˜ëŠ” ì§€ì—­ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤.
        """
        return self.forecast_service.get_supported_locations()
 